{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "url = 'C:\\\\Users\\\\user\\\\Desktop\\\\ML\\\\PROJECT\\\\CTR_SampleData'\n",
    "df= pd.read_csv(url, header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null/missing data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking varieties in each feature\n",
    "df.apply(pd.Series.nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(x='click',data=df, palette='hls')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "c= df.corr()\n",
    "sb.heatmap(c)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing 'hour' format\n",
    "df['hour']=pd.to_datetime(df['hour'],format='%y%m%d%H')\n",
    "df['dayOfMonth']=df['hour'].dt.day\n",
    "df['hou']=df['hour'].dt.hour\n",
    "df=df.drop(['hour'],axis=1)\n",
    "df = df.rename(columns={'hou': 'hour'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_obj_to_int(self):\n",
    "    \n",
    "    object_list_columns = self.columns\n",
    "    object_list_dtypes = self.dtypes\n",
    "    new_col_suffix = '_int'\n",
    "    for index in range(0,len(object_list_columns)):\n",
    "        if object_list_dtypes[index] == object :\n",
    "            self[object_list_columns[index]+new_col_suffix] = self[object_list_columns[index]].map( lambda  x: hash(x))\n",
    "            self.drop([object_list_columns[index]],inplace=True,axis=1)\n",
    "    return self\n",
    "df = convert_obj_to_int(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.click\n",
    "X=df.drop('click',axis=1)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/avazu-ctr-prediction/discussion/10819#58338\n",
    "\n",
    "NULLs for siteid, sitedomain, site_category: 85f751fd, c4e18dd6, 50e219e0\n",
    "\n",
    "NULLs for appid, appdomain, app_category: ecad2386, 7801e8d9, 07d7df22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si=df.loc[df.site_id == '85f751fd', 'site_id'].count()\n",
    "si/1000000*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdm=df.loc[df.site_domain== 'c4e18dd6', 'site_domain'].count()\n",
    "sdm/1000000*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=df.loc[df.site_category == '50e219e0', 'site_category'].count()\n",
    "sc/1000000*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api=df.loc[df.app_id == 'ecad2386', 'app_id'].count()\n",
    "api/1000000*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apdm=df.loc[df.app_domain== '7801e8d9', 'app_domain'].count()\n",
    "apdm/1000000*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apc=df.loc[df.app_category == '07d7df22', 'app_category'].count()\n",
    "apc/1000000*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "# replace '-2' values with null values\n",
    "df[[site_id]] = df[[site_id]].replace(-2, 85f751fd)\n",
    "# count the number of nan values in each column\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on data where missing values cause errors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# define the model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define the model evaluation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# evaluate the model\n",
    "result = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "# report the mean performance\n",
    "print('Accuracy: %.3f' % result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "# summarize the shape of the data with missing rows removed\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on data after removed missing data\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define the model evaluation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# evaluate the model\n",
    "result = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "# report the mean performance\n",
    "print('Accuracy: %.3f' % result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report which features were selected by RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=10)\n",
    "\n",
    "rfe.fit(X, y)\n",
    "# summarize all features\n",
    "for i in range(X.shape[1]):\n",
    "\tprint('Column: %d, Selected=%s, Rank: %d' % (i, rfe.support_[i], rfe.ranking_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# feature extraction\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(x, y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance with XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance using built-in function\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X, y)\n",
    "# plot feature importance\n",
    "plot_importance(model)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance with RandomForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "features = df_X.columns\n",
    "rnd_clf = RandomForestClassifier( n_jobs=-1, random_state=0)\n",
    "rnd_clf.fit(df_X, df_y)\n",
    "importances = rnd_clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(13,13))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='skyblue', align='center',height=0.9)\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z-score\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "z = np.abs(stats.zscore(X))\n",
    "df_o=X\n",
    "df_o =df_o[(z < 3).all(axis=1)]\n",
    "\n",
    "df_o.shape\n",
    "\n",
    "lst1=df_o.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = x_train.quantile(0.25)\n",
    "Q3 = x_train.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df_o2 = X[~((X < (Q1 - 1.5 * IQR)) |(X > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "df_o2.shape\n",
    "\n",
    "lst2=df_o2.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from collections import Counter\n",
    "\n",
    "clf=IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.12), \\\n",
    "                        max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
    "\n",
    "clf.fit(X)\n",
    "isof_outliers = clf.predict(X)\n",
    "iso=isof_outliers.tolist()\n",
    "Counter(iso)\n",
    "listOfTrainIndexes=X.index.tolist()\n",
    "\n",
    "lst3=[]\n",
    "for i in range(len(iso)):\n",
    "    if iso[i]==1:\n",
    "        lst3.append(listOfTrainIndexes[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultLst=np.unique(lst1+lst2+lst3)\n",
    "len(resultLst) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ordinal encode/One-hot encode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input', X.shape)\n",
    "print('Output', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal encode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# ordinal encode input variables\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "X_ore = ordinal_encoder.fit_transform(X)\n",
    "# ordinal encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_ore = label_encoder.fit_transform(y)\n",
    "# summarize the transformed data\n",
    "print('Input', X_ore.shape)\n",
    "print(X_ore[:5, :])\n",
    "print('Output', y_ore.shape)\n",
    "print(y_ore[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate logistic regression with an ordinal encoding\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X,y=X_ore,y_ore\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# ordinal encode input variables\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_encoder.fit(X_train)\n",
    "X_train = ordinal_encoder.transform(X_train)\n",
    "X_test = ordinal_encoder.transform(X_test)\n",
    "# ordinal encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# one hot encode input variables\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "X_ohe = onehot_encoder.fit_transform(X)\n",
    "# ordinal encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_ohe = label_encoder.fit_transform(y)\n",
    "# summarize the transformed data\n",
    "print('Input', X_ohe.shape)\n",
    "print(X_ohe[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate logistic regression with an one-hot encoding\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X,y=X_ohe,y_ohe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# one-hot encode input variables\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_encoder.fit(X_train)\n",
    "X_train = onehot_encoder.transform(X_train)\n",
    "X_test = onehot_encoder.transform(X_test)\n",
    "# ordinal encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA** (Principal Component Analysis), might be the most popular technique for dimensionality reduction with dense data (few zero values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate pca with logistic regression algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# define the pipeline\n",
    "steps = [('pca', PCA(n_components=10)), ('m', LogisticRegression())]\n",
    "model = Pipeline(steps=steps)\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVD** (Singular Value Decomposition), is one of the most popular techniques for dimensionality reduction for sparse data (data with many zero values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate svd with logistic regression algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# define the pipeline\n",
    "steps = [('svd', TruncatedSVD(n_components=10)), ('m', LogisticRegression())]\n",
    "model = Pipeline(steps=steps)\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LDA** (Linear Discriminant Analysis), is a multi-class classification algorithm that can be used for dimensionality reduction.\n",
    "\n",
    "The number of dimensions for the projection is limited to 1 and C-1, where C is the number of classes. In this case, our dataset is a binary classification problem (two classes), limiting the number of dimensions to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate lda with logistic regression algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = x_train\n",
    "y = y_train\n",
    "# define the pipeline\n",
    "steps = [('lda', LinearDiscriminantAnalysis(n_components=1)), ('m', LogisticRegression())]\n",
    "model = Pipeline(steps=steps)\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalancing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling imbalanced training data with SMOTE\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X=X\n",
    "y=y\n",
    "# count class(click 0 and 1) dist.\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "#  new class dist\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "counter = Counter(y)\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling imbalanced training data with SMOTE and random undersample\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "X=X\n",
    "y=y\n",
    "\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "over_samp = SMOTE(sampling_strategy=0.3)\n",
    "under_samp = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over_samp), ('u', under_samp)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "X, y = pipeline.fit_resample(X, y)\n",
    "\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borderline-SMOTE with SVM \n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "\n",
    "X=X\n",
    "y=y\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "oversample = SVMSMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC vs. Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ROC curves** should be used when there are roughly equal numbers of observations for each class.\n",
    "- **Precision-Recall curves** should be used when there is a moderate to large class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve and auc on an imbalanced dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "# generate 2 class dataset\n",
    "X, y =X_ore, y_ore\n",
    "# split into train/test sets\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(testy))]\n",
    "# fit a model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(trainX, trainy)\n",
    "# predict probabilities\n",
    "lr_probs = model.predict_proba(testX)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(testy, ns_probs)\n",
    "lr_auc = roc_auc_score(testy, lr_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision-recall curve and f1 for an imbalanced dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    "# generate 2 class dataset\n",
    "X, y = X_ore, y_ore\n",
    "# split into train/test sets\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "# fit a model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(trainX, trainy)\n",
    "# predict probabilities\n",
    "lr_probs = model.predict_proba(testX)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# predict class values\n",
    "yhat = model.predict(testX)\n",
    "# calculate precision and recall for each threshold\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(testy, lr_probs)\n",
    "# calculate scores\n",
    "lr_f1, lr_auc = f1_score(testy, yhat), auc(lr_recall, lr_precision)\n",
    "# summarize scores\n",
    "print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
    "# plot the precision-recall curves\n",
    "no_skill = len(testy[testy==1]) / len(testy)\n",
    "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_recall, lr_precision, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
